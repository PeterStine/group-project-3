{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indeed_data_cleaning.py\n",
    "\n",
    "---\n",
    "\n",
    "## This will clean the data that was scraped from Indeed.  The location strings will be cleaned into usable locations to feed into Geoapify, coordinates will be determined with Geoapify when possible, and each listing will be tagged as In_person, Hybrid, or Remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Dependencies and Setup\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import requests\n",
    "    import json\n",
    "    from geoapify_function import single_geocode\n",
    "\n",
    "    # Import the API key for Geoapify\n",
    "    from config import geoapify_key\n",
    "    \n",
    "    # Open a file to save logs to\n",
    "    t = time.localtime()\n",
    "    current_time_file = time.strftime(\"%Y-%m-%d-%H-%M-%S\", t)\n",
    "\n",
    "    log = open(f\"../logs/cleaning_log_{current_time_file}.txt\", \"a\")\n",
    "    log_file = f\"../logs/cleaning_log_{current_time_file}.txt\"\n",
    "    \n",
    "except:\n",
    "    # Open a file to save logs to\n",
    "    t = time.localtime()\n",
    "    current_time_file = time.strftime(\"%Y-%m-%d-%H-%M-%S\", t)\n",
    "\n",
    "    log = open(f\"../logs/cleaning_log_{current_time_file}.txt\", \"a\")\n",
    "    log_file = f\"../logs/cleaning_log_{current_time_file}.txt\"\n",
    "\n",
    "    print(\"Something went wrong with importing dependencies, possibly with the Geoapify key or custom geocode function\", file=log)\n",
    "    print(\"Something went wrong with importing dependencies, possibly with the Geoapify key or custom geocode function\")\n",
    "    \n",
    "    print(f\"Logs have been saved to {log_file}\", file=log)\n",
    "    print(f\"Logs have been saved to {log_file}\")\n",
    "    \n",
    "    log.close()\n",
    "    quit()\n",
    "    \n",
    "# Check if an uncleaned file exists\n",
    "try:\n",
    "    # Import uncleaned scraped data\n",
    "    file_path_new = '../data/listings_new.csv'\n",
    "    listings_scraped_df = pd.read_csv(file_path_new)\n",
    "\n",
    "    # Count the total listings\n",
    "    listings_count = listings_scraped_df['id'].count()\n",
    "    #print(listings_count)\n",
    "\n",
    "    # Check that data seems to have loaded correctly\n",
    "    t = time.localtime()\n",
    "    current_time_file = time.strftime(\"%Y-%m-%d-%H-%M-%S\", t)\n",
    "    \n",
    "    print(\"New data loaded from file successfully!\", file=log)\n",
    "    print(\"New data loaded from file successfully!\")\n",
    "    \n",
    "except:\n",
    "    print(\"Something went wrong with loading the uncleaned file\", file=log)\n",
    "    print(\"Something went wrong with loading the uncleaned file\")\n",
    "    \n",
    "    print(f\"Logs have been saved to {log_file}\", file=log)\n",
    "    print(f\"Logs have been saved to {log_file}\")\n",
    "    \n",
    "    log.close()\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of this column for later use\n",
    "locations = listings_scraped_df['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame which contains only in_person jobs\n",
    "listings_office_df = listings_scraped_df.loc[~locations.str.startswith('Remote') & ~locations.str.startswith('Hybrid remote')].copy()\n",
    "\n",
    "# Create a column indicating these are in_person jobs\n",
    "listings_office_df['office'] = 'in_person'\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "# Get lat, lon for each location\n",
    "# Create empty lists to hold coordinates\n",
    "\n",
    "print(f\"Beginning Geoapify requests for In_person listings...\\n{current_time}\", file=log)\n",
    "print(f\"Beginning Geoapify requests for In_person listings...\\n{current_time}\")\n",
    "\n",
    "lats_office = []\n",
    "lons_office = []\n",
    "\n",
    "for place in listings_office_df['location']:\n",
    "    try:\n",
    "        lat, lon = single_geocode(place)\n",
    "    except:\n",
    "        lat, lon = None, None\n",
    "    \n",
    "    lats_office.append(lat)\n",
    "    lons_office.append(lon)\n",
    "    \n",
    "listings_office_df['lat'] = lats_office\n",
    "listings_office_df['lon'] = lons_office\n",
    "        \n",
    "# Count the results for in_person listings\n",
    "office_count = listings_office_df['id'].count()\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "print(f\"Completed Geoapify requests for {office_count} In_person listings\\n{current_time}.\", file=log)\n",
    "print(f\"Completed Geoapify requests for {office_count} In_person listings\\n{current_time}.\")\n",
    "\n",
    "#listings_office_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame which contains only Hybrid Remote jobs\n",
    "listings_hybrid_df = listings_scraped_df.loc[locations.str.startswith('Hybrid remote')].copy()\n",
    "\n",
    "# Create a column indicating these are not in_person jobs\n",
    "listings_hybrid_df['office'] = 'hybrid'\n",
    "\n",
    "# Remove extra text from location to leave only the city, state (zip)\n",
    "listings_hybrid_df['location'] = listings_hybrid_df['location'].str.strip('Hybrid remote in ')\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "# Get lat, lon for each location\n",
    "# Create empty lists to hold coordinates\n",
    "\n",
    "print(f\"Beginning Geoapify requests for Hybrid listings...\\n{current_time}\", file=log)\n",
    "print(f\"Beginning Geoapify requests for Hybrid listings...\\n{current_time}\")\n",
    "\n",
    "lats_hybrid = []\n",
    "lons_hybrid = []\n",
    "\n",
    "for place in listings_hybrid_df['location']:\n",
    "    try:\n",
    "        lat, lon = single_geocode(place)\n",
    "    except:\n",
    "        lat, lon = None, None\n",
    "    \n",
    "    lats_hybrid.append(lat)\n",
    "    lons_hybrid.append(lon)\n",
    "    \n",
    "listings_hybrid_df['lat'] = lats_hybrid\n",
    "listings_hybrid_df['lon'] = lons_hybrid\n",
    "\n",
    "# Count the results for hybrid listings\n",
    "hybrid_count = listings_hybrid_df['id'].count()\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "print(f\"Completed Geoapify requests for {hybrid_count} Hybrid listings\\n{current_time}.\", file=log)\n",
    "print(f\"Completed Geoapify requests for {hybrid_count} Hybrid listings\\n{current_time}.\")\n",
    "\n",
    "#listings_hybrid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame which contains only Remote jobs\n",
    "listings_remote_raw_df = listings_scraped_df.loc[locations.str.startswith('Remote')].copy()\n",
    "\n",
    "# Create a column indicating these are not in_person jobs\n",
    "listings_remote_raw_df['office'] = 'remote'\n",
    "\n",
    "# Split this DataFrame into one that has a location for each job and one that does not\n",
    "\n",
    "# Contains a location\n",
    "listings_remote_loc_df = listings_remote_raw_df.loc[listings_remote_raw_df['location'].str.startswith('Remote in ')].copy()\n",
    "# Remove extra text from location to leave only the city, state (zip)\n",
    "listings_remote_loc_df['location'] = listings_remote_loc_df['location'].str.strip('Remote in ')\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "# Get lat, lon for each location\n",
    "# Create empty lists to hold coordinates\n",
    "\n",
    "print(f\"Beginning Geoapify requests for Remote listings...\\n{current_time}\", file=log)\n",
    "print(f\"Beginning Geoapify requests for Remote listings...\\n{current_time}\")\n",
    "\n",
    "lats_remote = []\n",
    "lons_remote = []\n",
    "\n",
    "for place in listings_remote_loc_df['location']:\n",
    "    try:\n",
    "        lat, lon = single_geocode(place)\n",
    "    except:\n",
    "        lat,lon = None, None\n",
    "    \n",
    "    lats_remote.append(lat)\n",
    "    lons_remote.append(lon)\n",
    "    \n",
    "listings_remote_loc_df['lat'] = lats_remote\n",
    "listings_remote_loc_df['lon'] = lons_remote\n",
    "\n",
    "# Does not have a location\n",
    "listings_remote_only_df = listings_remote_raw_df.loc[~listings_remote_raw_df['location'].str.startswith('Remote in ')].copy()\n",
    "listings_remote_only_df['lat'] = 42.447317\n",
    "listings_remote_only_df['lon'] = -71.224500\n",
    "\n",
    "# Put the two DataFrames back together\n",
    "listings_remote_df = pd.concat([listings_remote_loc_df, listings_remote_only_df])\n",
    "\n",
    "# Count the results for remote listings\n",
    "remote_count = listings_remote_df['id'].count()\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "print(f\"Completed Geoapify requests for {remote_count} Remote listings\\n{current_time}.\", file=log)\n",
    "print(f\"Completed Geoapify requests for {remote_count} Remote listings\\n{current_time}.\")\n",
    "\n",
    "#listings_remote_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any listings were lost or duplicated\n",
    "if ((office_count + hybrid_count + remote_count) == listings_count):\n",
    "    print(f\"{listings_count} listings were successfully cleaned!\", file=log)\n",
    "    print(f\"{listings_count} listings were successfully cleaned!\")\n",
    "\n",
    "elif ((office_count + hybrid_count + remote_count) > listings_count):\n",
    "    print(f\"Some listings may have been duplicated during cleaning.\", file=log)\n",
    "    print(f\"Some listings may have been duplicated during cleaning.\")\n",
    "          \n",
    "elif ((office_count + hybrid_count + remote_count) < listings_count):\n",
    "    print(f\"Some listings may have been lost during cleaning.\", file=log)\n",
    "    print(f\"Some listings may have been lost during cleaning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the three DataFrames back together\n",
    "listings_temp_df = pd.concat([listings_office_df, listings_hybrid_df])\n",
    "\n",
    "listings_cleaned_df = pd.concat([listings_temp_df, listings_remote_df])\n",
    "\n",
    "# Reordering the columns\n",
    "listings_cleaned_df = listings_cleaned_df[['id', 'title', 'company', 'location', 'lat', 'lon', 'office', 'job_type', 'salary', 'time_recorded', 'url']]\n",
    "\n",
    "#listings_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame as a .csv file\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "current_time_file = time.strftime(\"%Y-%m-%d-%H-%M-%S\", t)\n",
    "\n",
    "# Check if an archived file exists and concatenate to it if so\n",
    "try:\n",
    "    file_path_archive = '../data/listings_cleaned.csv'\n",
    "    \n",
    "    # Import cleaned archive data\n",
    "    listings_archive_df = pd.read_csv(file_path_archive)\n",
    "\n",
    "    # Drops the column that contains the .csv row number\n",
    "    #listings_archive_df.drop(columns=listings_archive_df.columns[0], axis=1, inplace=True)\n",
    "    \n",
    "    # Save the archived file as a backup\n",
    "    listings_archive_df.to_csv(f\"{file_path_archive}_{current_time_file}\", index=False)\n",
    "    \n",
    "    # Concatenate new data onto the old\n",
    "    listings_concat_df = pd.concat([listings_archive_df, listings_cleaned_df])\n",
    "    \n",
    "    # Overwrite the archive file with the newly updated one\n",
    "    listings_concat_df.to_csv(file_path_archive, index=False)\n",
    "    print(f\"New cleaned results added to archive and saved to file {file_path_archive}\", file=log)\n",
    "    print(f\"New cleaned results added to archive and saved to file {file_path_archive}\")\n",
    "    print(f\"The previous data was saved as a backup file {file_path_archive}_{current_time_file}\", file=log)\n",
    "    print(f\"The previous data was saved as a backup file {file_path_archive}_{current_time_file}\")\n",
    "    \n",
    "\n",
    "except:\n",
    "    try:\n",
    "        file_path_write = '../data/listings_cleaned.csv'\n",
    "    \n",
    "        listings_cleaned_df.to_csv(file_path_write, index=False)\n",
    "        print(f\"New cleaned results saved to file {file_path_write}\", file=log)\n",
    "        print(f\"New cleaned results saved to file {file_path_write}\")\n",
    "        \n",
    "    except:\n",
    "        print(\"Something went wrong with saving the results to file\", file=log)\n",
    "        print(\"Something went wrong with saving the results to file\")\n",
    "    \n",
    "        print(f\"Logs have been saved to {log_file}\", file=log)\n",
    "        print(f\"Logs have been saved to {log_file}\")\n",
    "    \n",
    "        log.close()\n",
    "        quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
