{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1043318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import splinter\n",
    "from splinter import Browser\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162309f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 14:57:09\n"
     ]
    }
   ],
   "source": [
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3da61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create browser object\n",
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52db4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Indeed\n",
    "url = \"https://www.indeed.com/\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Give the browser time to respond\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a2debf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes the / from the end of the url\n",
    "url[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "070f1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array to store results in\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "174739a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all the posts on a single page\n",
    "def scrape_one_page(data, browser):\n",
    "    # Job Title\n",
    "    posts_in_page = browser.find_by_css(\".jobsearch-ResultsList\").find_by_css(\".job_seen_beacon\")\n",
    "        \n",
    "    for post in posts_in_page:\n",
    "        # Initialize 1D array to store this post's data\n",
    "        post_data = []\n",
    "            \n",
    "        # Grab job id\n",
    "        try:\n",
    "            job_id = post.find_by_css(\"a\").first[\"data-jk\"]\n",
    "            post_data.append(job_id)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab job title\n",
    "        try:\n",
    "            title = post.find_by_css(\"span\").first.text\n",
    "            post_data.append(title)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab company\n",
    "        try:\n",
    "            company = post.find_by_css(\".companyName\").first.text\n",
    "            post_data.append(company)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab location\n",
    "        try:\n",
    "            location = post.find_by_css(\".companyLocation\").first.text\n",
    "            post_data.append(location)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab job type (if available)\n",
    "        try:\n",
    "            job_type = post.find_by_css(\"[aria-label='Job type']\").first.find_by_xpath(\"..\").first.text\n",
    "            post_data.append(job_type)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "                \n",
    "        # Grab salary (if available)\n",
    "        try:\n",
    "            salary = post.find_by_css(\"[aria-label='Salary']\").first.find_by_xpath(\"..\").first.text\n",
    "            post_data.append(salary)\n",
    "        except:\n",
    "            try:\n",
    "                salary = post.find_by_css(\".estimated-salary\").first.find_by_css(\"span\").first.text\n",
    "                post_data.append(salary)\n",
    "            except:\n",
    "                post_data.append(None)\n",
    "                \n",
    "        # Record the time\n",
    "        t = time.localtime()\n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "        post_data.append(current_time)\n",
    "            \n",
    "        # Grab job url\n",
    "        try:\n",
    "            job_url = post.find_by_css(\"a\").first[\"href\"]\n",
    "            post_data.append(job_url)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "        \n",
    "        data.append(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "facb59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all the posts on all pages\n",
    "def indeed_scraper(data, search_params, browser):\n",
    "    base_url = url[:-1]\n",
    "    # Find the what box & search the job title\n",
    "    what = browser.find_by_id(\"text-input-what\").first\n",
    "    what.fill(search_params[\"what\"])\n",
    "    \n",
    "    # Find the where box & search for the location\n",
    "    where = browser.find_by_id(\"text-input-where\").first\n",
    "    where.type(Keys.CONTROL + \"a\")\n",
    "    where.type(Keys.BACKSPACE)\n",
    "    where.fill(search_params[\"where\"])\n",
    "    \n",
    "    where.type(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    date_posted = browser.find_by_text(\"Date posted\").first\n",
    "    date_posted.click()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # This can be set to one of these options = [\"Last 24 Hours\", \"Last 3 days\", \"Last 7 days\", \"Last 14 days\"]\n",
    "    last_24_hours = browser.find_by_text(\"Last 7 days\").first\n",
    "    last_24_hours.click()\n",
    "    \n",
    "    last_page = False\n",
    "    page_count = 0\n",
    "    \n",
    "    while not last_page:\n",
    "        try:  # This code runs for every page except the last page\n",
    "            next_page_button = browser.find_by_css(\"[aria-label='Next Page']\")\n",
    "            \n",
    "            page_count += 1\n",
    "            print(f\"Scraping page {page_count}...\")\n",
    "        \n",
    "            post_data = scrape_one_page(data, browser)\n",
    "                            \n",
    "            print(\"Clicking to next page.\")\n",
    "            next_page_button.click()\n",
    "                            \n",
    "        except:  # This code runs only for the last page\n",
    "            \n",
    "            page_count += 1\n",
    "            print(f\"Scraping final page of {page_count} total pages...\")\n",
    "        \n",
    "            post_data = scrape_one_page(data, browser)\n",
    "                            \n",
    "            print(\"Final page has been scraped.\")               \n",
    "            last_page = True\n",
    "                       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d0a6ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning scraping process...\n",
      "Scraping page 1...\n",
      "Clicking to next page.\n",
      "Scraping page 2...\n",
      "Clicking to next page.\n",
      "Scraping page 3...\n",
      "Clicking to next page.\n",
      "Scraping page 4...\n",
      "Clicking to next page.\n",
      "Scraping page 5...\n",
      "Clicking to next page.\n",
      "Scraping page 6...\n",
      "Clicking to next page.\n",
      "Scraping page 7...\n",
      "Clicking to next page.\n",
      "Scraping page 8...\n",
      "Clicking to next page.\n",
      "Scraping page 9...\n",
      "Clicking to next page.\n",
      "Scraping page 10...\n",
      "Clicking to next page.\n",
      "Scraping page 11...\n",
      "Clicking to next page.\n",
      "Scraping page 12...\n",
      "Clicking to next page.\n",
      "Scraping page 13...\n",
      "Clicking to next page.\n",
      "Scraping page 14...\n",
      "Clicking to next page.\n",
      "Scraping page 15...\n",
      "Clicking to next page.\n",
      "Scraping page 16...\n",
      "Clicking to next page.\n",
      "Scraping page 17...\n",
      "Clicking to next page.\n",
      "Scraping page 18...\n",
      "Clicking to next page.\n",
      "Scraping page 19...\n",
      "Clicking to next page.\n",
      "Scraping page 20...\n",
      "Clicking to next page.\n",
      "Scraping page 21...\n",
      "Clicking to next page.\n",
      "Scraping page 22...\n",
      "Clicking to next page.\n",
      "Scraping page 23...\n",
      "Clicking to next page.\n",
      "Scraping page 24...\n",
      "Clicking to next page.\n",
      "Scraping page 25...\n",
      "Clicking to next page.\n",
      "Scraping page 26...\n",
      "Clicking to next page.\n",
      "Scraping page 27...\n",
      "Clicking to next page.\n",
      "Scraping page 28...\n",
      "Clicking to next page.\n",
      "Scraping page 29...\n",
      "Clicking to next page.\n",
      "Scraping page 30...\n",
      "Clicking to next page.\n",
      "Scraping page 31...\n",
      "Clicking to next page.\n",
      "Scraping page 32...\n",
      "Clicking to next page.\n",
      "Scraping page 33...\n",
      "Clicking to next page.\n",
      "Scraping page 34...\n",
      "Clicking to next page.\n",
      "Scraping page 35...\n",
      "Clicking to next page.\n",
      "Scraping page 36...\n",
      "Clicking to next page.\n",
      "Scraping page 37...\n",
      "Clicking to next page.\n",
      "Scraping page 38...\n",
      "Clicking to next page.\n",
      "Scraping page 39...\n",
      "Clicking to next page.\n",
      "Scraping page 40...\n",
      "Clicking to next page.\n",
      "Scraping page 41...\n",
      "Clicking to next page.\n",
      "Scraping page 42...\n",
      "Clicking to next page.\n",
      "Scraping final page of 43 total pages...\n",
      "Final page has been scraped.\n",
      "Scraping completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set \"what\" for the words to search, and \"where\" for the location search\n",
    "search_params = {\"what\": \"Data Scientist\", \"where\": \"United States\"}\n",
    "\n",
    "# Run the webscraper to collect all listings from all pages for the last 24 hours\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "print(f\"Beginning scraping process...{current_time}\")\n",
    "try:\n",
    "    indeed_scraper(data, search_params, browser)\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "    print(f\"Scraping completed successfully! {current_time}\")\n",
    "    \n",
    "    browser.quit()\n",
    "    print(\"Browser has been closed.\")\n",
    "    \n",
    "except:\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "    print(f\"Something went wrong with the scraper.. :(\\n{current_time}\")\n",
    "    \n",
    "    browser.quit()\n",
    "    print(\"Browser has been closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7f002d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "      <th>salary</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1a7f4fc726420f4</td>\n",
       "      <td>Sr. Data Scientist- Risk Modeler, AVP - Hybrid</td>\n",
       "      <td>Citi</td>\n",
       "      <td>Elk Grove Village, IL 60007</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>$93,200 - $139,800 a year</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79f1c9abf1954819</td>\n",
       "      <td>Principal Data Scientist (Algorithm)</td>\n",
       "      <td>WALGREENS</td>\n",
       "      <td>Deerfield, IL 60015</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2c2b68ca8d6a565</td>\n",
       "      <td>Machine Learning Supervisor</td>\n",
       "      <td>Old Republic Title</td>\n",
       "      <td>Hybrid remote in Minnetonka, MN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Estimated $75.9K - $96.1K a year</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46883a8ae338078a</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Portland, ME 04101 \\n(West Bayside area)</td>\n",
       "      <td>None</td>\n",
       "      <td>Estimated $91.9K - $116K a year</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca739b233c19204c</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pacer Staffing</td>\n",
       "      <td>Durham, NC 27709</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>$39 an hour</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>efb7eae14cd641bb</td>\n",
       "      <td>Strategic Customers - Data Scientist</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>Estimated $102K - $129K a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=efb7eae14cd64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>b1e05778e5fce266</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>PowerSchool Group LLC</td>\n",
       "      <td>Remote in United States</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>$110,000 - $140,000 a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=b1e05778e5fce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>55ce5fa397772ed2</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Suzy, Inc.</td>\n",
       "      <td>Remote in United States</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>$128,000 - $150,000 a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=55ce5fa397772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>c46648244d8618b1</td>\n",
       "      <td>Principal Data Architect</td>\n",
       "      <td>FICO</td>\n",
       "      <td>United States</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>$147,000 - $231,000 a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c46648244d861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>c138e1459af453c0</td>\n",
       "      <td>Applied Scientist 4</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c138e1459af45...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           title  \\\n",
       "0    f1a7f4fc726420f4  Sr. Data Scientist- Risk Modeler, AVP - Hybrid   \n",
       "1    79f1c9abf1954819            Principal Data Scientist (Algorithm)   \n",
       "2    a2c2b68ca8d6a565                     Machine Learning Supervisor   \n",
       "3    46883a8ae338078a                                  Data Scientist   \n",
       "4    ca739b233c19204c                                  Data Scientist   \n",
       "..                ...                                             ...   \n",
       "620  efb7eae14cd641bb            Strategic Customers - Data Scientist   \n",
       "621  b1e05778e5fce266                           Senior Data Scientist   \n",
       "622  55ce5fa397772ed2                       Machine Learning Engineer   \n",
       "623  c46648244d8618b1                        Principal Data Architect   \n",
       "624  c138e1459af453c0                             Applied Scientist 4   \n",
       "\n",
       "                   company                                  location  \\\n",
       "0                     Citi               Elk Grove Village, IL 60007   \n",
       "1                WALGREENS                       Deerfield, IL 60015   \n",
       "2       Old Republic Title           Hybrid remote in Minnetonka, MN   \n",
       "3              Robert Half  Portland, ME 04101 \\n(West Bayside area)   \n",
       "4           Pacer Staffing                          Durham, NC 27709   \n",
       "..                     ...                                       ...   \n",
       "620                 Oracle                             United States   \n",
       "621  PowerSchool Group LLC                   Remote in United States   \n",
       "622             Suzy, Inc.                   Remote in United States   \n",
       "623                   FICO                             United States   \n",
       "624                 Oracle                             United States   \n",
       "\n",
       "      job_type                            salary  \\\n",
       "0    Full-time         $93,200 - $139,800 a year   \n",
       "1         None                              None   \n",
       "2    Full-time  Estimated $75.9K - $96.1K a year   \n",
       "3         None   Estimated $91.9K - $116K a year   \n",
       "4    Full-time                       $39 an hour   \n",
       "..         ...                               ...   \n",
       "620       None    Estimated $102K - $129K a year   \n",
       "621  Full-time        $110,000 - $140,000 a year   \n",
       "622  Full-time        $128,000 - $150,000 a year   \n",
       "623  Full-time        $147,000 - $231,000 a year   \n",
       "624       None                              None   \n",
       "\n",
       "                                                   url  \n",
       "0    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "1    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "2    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "3    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "4    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "..                                                 ...  \n",
       "620  https://www.indeed.com/rc/clk?jk=efb7eae14cd64...  \n",
       "621  https://www.indeed.com/rc/clk?jk=b1e05778e5fce...  \n",
       "622  https://www.indeed.com/rc/clk?jk=55ce5fa397772...  \n",
       "623  https://www.indeed.com/rc/clk?jk=c46648244d861...  \n",
       "624  https://www.indeed.com/rc/clk?jk=c138e1459af45...  \n",
       "\n",
       "[625 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name columns for putting the results into a DataFrame\n",
    "columns = [\"id\", \"title\", \"company\", \"location\", \"job_type\", \"salary\", \"time_recorded\", \"url\"]\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "listings_new_df = pd.DataFrame(data, columns = columns)\n",
    "listings_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame as a .csv file\n",
    "\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", t)\n",
    "\n",
    "file_path = '../data/listings_new.csv'\n",
    "\n",
    "listings_new_df.to_csv(file_path)\n",
    "print(f\"New results added and saved to file {file_path}\\n{current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d26da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
