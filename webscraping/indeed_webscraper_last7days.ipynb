{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1043318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import splinter\n",
    "from splinter import Browser\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3da61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create browser object\n",
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52db4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Indeed\n",
    "url = \"https://www.indeed.com/\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Give the browser time to respond\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2debf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes the / from the end of the url\n",
    "url[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070f1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array to store results in\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174739a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all the posts on a single page\n",
    "def scrape_one_page(data, browser):\n",
    "    # Job Title\n",
    "    posts_in_page = browser.find_by_css(\".jobsearch-ResultsList\").find_by_css(\".job_seen_beacon\")\n",
    "        \n",
    "    for post in posts_in_page:\n",
    "        # Initialize 1D array to store this post's data\n",
    "        post_data = []\n",
    "            \n",
    "        # Grab job id\n",
    "        try:\n",
    "            job_id = post.find_by_css(\"a\").first[\"data-jk\"]\n",
    "            post_data.append(job_id)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab job title\n",
    "        try:\n",
    "            title = post.find_by_css(\"span\").first.text\n",
    "            post_data.append(title)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab company\n",
    "        try:\n",
    "            company = post.find_by_css(\".companyName\").first.text\n",
    "            post_data.append(company)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab location\n",
    "        try:\n",
    "            location = post.find_by_css(\".companyLocation\").first.text\n",
    "            post_data.append(location)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "            \n",
    "        # Grab job type (if available)\n",
    "        try:\n",
    "            job_type = post.find_by_css(\"[aria-label='Job type']\").first.find_by_xpath(\"..\").first.text\n",
    "            post_data.append(job_type)\n",
    "        except:\n",
    "            post_data.append(None)\n",
    "                \n",
    "        # Grab salary (if available)\n",
    "        try:\n",
    "            salary = post.find_by_css(\"[aria-label='Salary']\").first.find_by_xpath(\"..\").first.text\n",
    "            post_data.append(salary)\n",
    "        except:\n",
    "            try:\n",
    "                salary = post.find_by_css(\".estimated-salary\").first.find_by_css(\"span\").first.text\n",
    "                post_data.append(salary)\n",
    "            except:\n",
    "                post_data.append(None)\n",
    "            \n",
    "        # Grab job url\n",
    "        job_url = post.find_by_css(\"a\").first[\"href\"]\n",
    "        post_data.append(job_url)\n",
    "        \n",
    "        data.append(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facb59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all the posts on all pages\n",
    "def indeed_scraper(data, search_params, browser):\n",
    "    base_url = url[:-1]\n",
    "    # Find the what box & search the job title\n",
    "    what = browser.find_by_id(\"text-input-what\").first\n",
    "    what.fill(search_params[\"what\"])\n",
    "    \n",
    "    # Find the where box & search for the location\n",
    "    where = browser.find_by_id(\"text-input-where\").first\n",
    "    where.type(Keys.CONTROL + \"a\")\n",
    "    where.type(Keys.BACKSPACE)\n",
    "    where.fill(search_params[\"where\"])\n",
    "    \n",
    "    where.type(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    date_posted = browser.find_by_text(\"Date posted\").first\n",
    "    date_posted.click()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # This can be set to one of these options = [\"Last 24 Hours\", \"Last 3 days\", \"Last 7 days\", \"Last 14 days\"]\n",
    "    last_24_hours = browser.find_by_text(\"Last 7 days\").first\n",
    "    last_24_hours.click()\n",
    "    \n",
    "    last_page = False\n",
    "    page_count = 0\n",
    "    \n",
    "    while not last_page:\n",
    "        try:  # This code runs for every page except the last page\n",
    "            next_page_button = browser.find_by_css(\"[aria-label='Next Page']\")\n",
    "            \n",
    "            page_count += 1\n",
    "            print(f\"Scraping page {page_count}...\")\n",
    "        \n",
    "            post_data = scrape_one_page(data, browser)\n",
    "                            \n",
    "            print(\"Clicking to next page.\")\n",
    "            next_page_button.click()\n",
    "                            \n",
    "        except:  # This code runs only for the last page\n",
    "            \n",
    "            page_count += 1\n",
    "            print(f\"Scraping final page of {page_count} total pages...\")\n",
    "        \n",
    "            post_data = scrape_one_page(data, browser)\n",
    "                            \n",
    "            print(\"Final page has been scraped.\")               \n",
    "            last_page = True\n",
    "                       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0a6ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning scraping process...\n",
      "Scraping page 1...\n",
      "Clicking to next page.\n",
      "Scraping page 2...\n",
      "Clicking to next page.\n",
      "Scraping page 3...\n",
      "Clicking to next page.\n",
      "Scraping page 4...\n",
      "Clicking to next page.\n",
      "Scraping page 5...\n",
      "Clicking to next page.\n",
      "Scraping page 6...\n",
      "Clicking to next page.\n",
      "Scraping page 7...\n",
      "Clicking to next page.\n",
      "Scraping page 8...\n",
      "Clicking to next page.\n",
      "Scraping page 9...\n",
      "Clicking to next page.\n",
      "Scraping page 10...\n",
      "Clicking to next page.\n",
      "Scraping page 11...\n",
      "Clicking to next page.\n",
      "Scraping page 12...\n",
      "Clicking to next page.\n",
      "Scraping page 13...\n",
      "Clicking to next page.\n",
      "Scraping page 14...\n",
      "Clicking to next page.\n",
      "Scraping page 15...\n",
      "Clicking to next page.\n",
      "Scraping page 16...\n",
      "Clicking to next page.\n",
      "Scraping page 17...\n",
      "Clicking to next page.\n",
      "Scraping page 18...\n",
      "Clicking to next page.\n",
      "Scraping page 19...\n",
      "Clicking to next page.\n",
      "Scraping page 20...\n",
      "Clicking to next page.\n",
      "Scraping page 21...\n",
      "Clicking to next page.\n",
      "Scraping page 22...\n",
      "Clicking to next page.\n",
      "Scraping page 23...\n",
      "Clicking to next page.\n",
      "Scraping page 24...\n",
      "Clicking to next page.\n",
      "Scraping page 25...\n",
      "Clicking to next page.\n",
      "Scraping page 26...\n",
      "Clicking to next page.\n",
      "Scraping page 27...\n",
      "Clicking to next page.\n",
      "Scraping page 28...\n",
      "Clicking to next page.\n",
      "Scraping page 29...\n",
      "Clicking to next page.\n",
      "Scraping page 30...\n"
     ]
    }
   ],
   "source": [
    "# Set \"what\" for the words to search, and \"where\" for the location search\n",
    "search_params = {\"what\": \"Data Scientist\", \"where\": \"United States\"}\n",
    "\n",
    "# Run the webscraper to collect all listings from all pages for the last 24 hours\n",
    "print(\"Beginning scraping process...\")\n",
    "try:\n",
    "    indeed_scraper(data, search_params, browser)\n",
    "    print(\"Scraping completed successfully!\")\n",
    "    \n",
    "    browser.quit()\n",
    "    print(\"Browser has been closed.\")\n",
    "    \n",
    "except:\n",
    "    print(\"Something went wrong with the scraper.. :(\")\n",
    "    \n",
    "    browser.quit()\n",
    "    print(\"Browser has been closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05908c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser has been closed.\n"
     ]
    }
   ],
   "source": [
    "browser.quit()\n",
    "print(\"Browser has been closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f002d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "      <th>salary</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7512ba2b05e1ba52</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CorTech, LLC</td>\n",
       "      <td>Hybrid remote in Research Triangle Park, NC 27709</td>\n",
       "      <td>None</td>\n",
       "      <td>$39.37 an hour</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>688e16f6ae2c5cce</td>\n",
       "      <td>Mid-Level ORSA / Data Scientist</td>\n",
       "      <td>Peraton</td>\n",
       "      <td>Fort Meade, MD 20755</td>\n",
       "      <td>None</td>\n",
       "      <td>$146,000 - $234,000 a year</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0a069bb20f180da</td>\n",
       "      <td>Consultant SME (Principal Data Scientist-Data ...</td>\n",
       "      <td>Experis</td>\n",
       "      <td>Remote in Raleigh, NC 27609</td>\n",
       "      <td>None</td>\n",
       "      <td>Estimated $128K - $162K a year</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca739b233c19204c</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pacer Staffing</td>\n",
       "      <td>Durham, NC 27709</td>\n",
       "      <td>None</td>\n",
       "      <td>$39 an hour</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3cd0c6a8ff3d8df5</td>\n",
       "      <td>Vice President Data Architect Lead Analyst - R...</td>\n",
       "      <td>Citi</td>\n",
       "      <td>Rutherford, NJ 07070</td>\n",
       "      <td>None</td>\n",
       "      <td>$137,610 - $206,420 a year</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>c9448c293d6fdd9f</td>\n",
       "      <td>Sr Data Analyst, Growth</td>\n",
       "      <td>Ollie Pet</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>Estimated $71.4K - $90.4K a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c9448c293d6fd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>bb61cca8c13df816</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Galen College of Nursing</td>\n",
       "      <td>Hybrid remote in Louisville, KY 40207</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=bb61cca8c13df...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>de9595496ad68832</td>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>WebstaurantStore</td>\n",
       "      <td>Remote in Lititz, PA 17543</td>\n",
       "      <td>None</td>\n",
       "      <td>$70,000 - $110,000 a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=de9595496ad68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>59c17ef70e1fe45a</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Neo.Tax</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>None</td>\n",
       "      <td>$170,000 - $190,000 a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=59c17ef70e1fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>da63c9ec4b9a57f9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Etsy</td>\n",
       "      <td>Remote in Brooklyn, NY 11201</td>\n",
       "      <td>None</td>\n",
       "      <td>$130,000 - $164,000 a year</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=da63c9ec4b9a5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              title  \\\n",
       "0    7512ba2b05e1ba52                                     Data Scientist   \n",
       "1    688e16f6ae2c5cce                    Mid-Level ORSA / Data Scientist   \n",
       "2    b0a069bb20f180da  Consultant SME (Principal Data Scientist-Data ...   \n",
       "3    ca739b233c19204c                                     Data Scientist   \n",
       "4    3cd0c6a8ff3d8df5  Vice President Data Architect Lead Analyst - R...   \n",
       "..                ...                                                ...   \n",
       "98   c9448c293d6fdd9f                            Sr Data Analyst, Growth   \n",
       "99   bb61cca8c13df816                                     Data Scientist   \n",
       "100  de9595496ad68832                             Applied Data Scientist   \n",
       "101  59c17ef70e1fe45a                              Senior Data Scientist   \n",
       "102  da63c9ec4b9a57f9                              Senior Data Scientist   \n",
       "\n",
       "                      company  \\\n",
       "0                CorTech, LLC   \n",
       "1                     Peraton   \n",
       "2                     Experis   \n",
       "3              Pacer Staffing   \n",
       "4                        Citi   \n",
       "..                        ...   \n",
       "98                  Ollie Pet   \n",
       "99   Galen College of Nursing   \n",
       "100          WebstaurantStore   \n",
       "101                   Neo.Tax   \n",
       "102                      Etsy   \n",
       "\n",
       "                                              location job_type  \\\n",
       "0    Hybrid remote in Research Triangle Park, NC 27709     None   \n",
       "1                                 Fort Meade, MD 20755     None   \n",
       "2                          Remote in Raleigh, NC 27609     None   \n",
       "3                                     Durham, NC 27709     None   \n",
       "4                                 Rutherford, NJ 07070     None   \n",
       "..                                                 ...      ...   \n",
       "98                                              Remote     None   \n",
       "99               Hybrid remote in Louisville, KY 40207     None   \n",
       "100                         Remote in Lititz, PA 17543     None   \n",
       "101                                  Mountain View, CA     None   \n",
       "102                       Remote in Brooklyn, NY 11201     None   \n",
       "\n",
       "                               salary  \\\n",
       "0                      $39.37 an hour   \n",
       "1          $146,000 - $234,000 a year   \n",
       "2      Estimated $128K - $162K a year   \n",
       "3                         $39 an hour   \n",
       "4          $137,610 - $206,420 a year   \n",
       "..                                ...   \n",
       "98   Estimated $71.4K - $90.4K a year   \n",
       "99                               None   \n",
       "100         $70,000 - $110,000 a year   \n",
       "101        $170,000 - $190,000 a year   \n",
       "102        $130,000 - $164,000 a year   \n",
       "\n",
       "                                                   url  \n",
       "0    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "1    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "2    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "3    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "4    https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "..                                                 ...  \n",
       "98   https://www.indeed.com/rc/clk?jk=c9448c293d6fd...  \n",
       "99   https://www.indeed.com/rc/clk?jk=bb61cca8c13df...  \n",
       "100  https://www.indeed.com/rc/clk?jk=de9595496ad68...  \n",
       "101  https://www.indeed.com/rc/clk?jk=59c17ef70e1fe...  \n",
       "102  https://www.indeed.com/rc/clk?jk=da63c9ec4b9a5...  \n",
       "\n",
       "[103 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name columns for putting the results into a DataFrame\n",
    "columns = [\"id\", \"title\", \"company\", \"location\", \"job_type\", \"salary\", \"url\"]\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "listings_new_df = pd.DataFrame(data, columns = columns)\n",
    "listings_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c85d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New results added and saved to file ../data/listings_all.csv\n"
     ]
    }
   ],
   "source": [
    "# Open the .csv file which contains all the previously collected listings\n",
    "try:\n",
    "    file_path = \"../data/listings_all.csv\"\n",
    "\n",
    "    listings_archive_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drops the row number from the .csv file so it doesn't load as a new column\n",
    "    listings_archive_df.drop(columns=listings_archive_df.columns[0], axis=1, inplace=True)\n",
    "    listings_archive_df.head()\n",
    "\n",
    "\n",
    "    # Append the new listings to the existing ones\n",
    "    listings_all_df = pd.concat([listings_archive_df, listings_new_df])\n",
    "\n",
    "\n",
    "    # Save the updated DataFrame as a .csv file\n",
    "    listings_all_df.to_csv(f'../data/listings_all.csv')\n",
    "    print(f\"New results added and saved to file {file_path}\")\n",
    "    \n",
    "except:\n",
    "    print(\"Something went wrong with loading and appending to the archived file.\\nPossibly no previous file existed.\\nNew results are being saved.\")\n",
    "    \n",
    "    # Save the updated DataFrame as a .csv file\n",
    "    listings_new_df.to_csv(f'../data/listings_all.csv')\n",
    "    print(f\"New results saved to file {file_path}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4302fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6865c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
